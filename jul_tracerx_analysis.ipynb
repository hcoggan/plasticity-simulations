{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbe68fd-a0a6-4714-8cb8-1680271e1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import njit\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "base_filepath = \"/Users/44749/Documents/PhD_work/datasets_for_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e758a6c8-bb53-4ba9-90c2-c64e6d6fb4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table loaded\n",
      "ARHGAP35 1 3\n",
      "MGA 2 3\n",
      "WRN 2 3\n",
      "CRUK0001 clonal drivers []\n",
      "EP300 1 3\n",
      "MET 1 3\n",
      "CRUK0002 clonal drivers []\n",
      "PIK3CA 3 5\n",
      "CRUK0003 clonal drivers []\n",
      "SMAD4 1 4\n",
      "CRUK0004 clonal drivers []\n",
      "PASK 1 4\n",
      "CRUK0005 clonal drivers []\n",
      "FANCC 1 2\n",
      "KEAP1 2 2\n",
      "MAP3K1 1 2\n",
      "PLCG2 2 2\n",
      "PLXNB2 2 2\n",
      "TP53 1 2\n",
      "CRUK0006 clonal drivers ['KEAP1', 'PLCG2', 'PLXNB2']\n",
      "U2AF1 2 2\n",
      "CRUK0008 clonal drivers ['U2AF1']\n",
      "ARHGAP35 1 4\n",
      "KMT2C 3 4\n",
      "CRUK0009 clonal drivers []\n",
      "CHD8 2 2\n",
      "CRUK0010 clonal drivers ['CHD8']\n",
      "FLT4 1 3\n",
      "KLF6 2 3\n",
      "KRAS 2 3\n",
      "NBN 4 3\n",
      "CRUK0011 clonal drivers []\n",
      "EGFR 2 2\n",
      "CRUK0012 clonal drivers ['EGFR']\n",
      "CRUK0013 clonal drivers []\n",
      "KRAS 2 2\n",
      "TP53 2 2\n",
      "CRUK0014 clonal drivers ['KRAS', 'TP53']\n",
      "BAP1 2 2\n",
      "EGFR 1 2\n",
      "CRUK0015 clonal drivers ['BAP1']\n",
      "CBLB 2 2\n",
      "FAT1 2 2\n",
      "SPEN 2 2\n",
      "CRUK0016 clonal drivers ['CBLB', 'FAT1', 'SPEN']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34208\\1934376405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m#print(len(relevant_muts))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelevant_muts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mmutID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ref'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'var'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hugo_Symbol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_mut_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DriverMut'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mccf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_ccf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_clonality'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'clonal'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m#print(tID, regID, mutID, ccf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m         \u001b[1;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3775\u001b[0m     \u001b[1;31m# Indexing Methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3777\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3778\u001b[0m         \"\"\"\n\u001b[0;32m   3779\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#read in mutations and correct for clonality\n",
    "df = pd.read_csv(\"C:/Users/44749/Documents/PhD_work/datasets_for_analysis/full_tx421primary_muttable_vaf_ccf_clonality.csv\")\n",
    "\n",
    "print(\"Table loaded\")\n",
    "\n",
    "filtered_df= df[df['PASS'] == True & (df['Timing_SC'] != \"E\")]\n",
    "\n",
    "unique_tumours = filtered_df[['cruk_tumour_id']].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "#translate table into dictionary\n",
    "\n",
    "driver_mut_dict = {True:1, False:0}\n",
    "all_tumour_names = []\n",
    "\n",
    "for tumour in unique_tumours.values.tolist():\n",
    "    tID = tumour[0]\n",
    "    all_drivs_found = []\n",
    "    clonal_appearances_of_drivers = {}\n",
    "    all_tumour_names.append(tID)\n",
    "    df_here = filtered_df[filtered_df['cruk_tumour_id'] == tID]\n",
    "    unique_regions = df_here[['region']].drop_duplicates()\n",
    "    #print(unique_regions)\n",
    "    tumour_regions = [{} for m in range(len(unique_regions.values.tolist()))]\n",
    "    #print(unique_regions)\n",
    "    for n, region in enumerate(unique_regions.values.tolist()):\n",
    "        regID = region[0]\n",
    "        #print(tID, regID)\n",
    "        relevant_muts = df_here[df_here['region']==regID]\n",
    "        #print(len(relevant_muts))\n",
    "        for index, row in relevant_muts.iterrows():\n",
    "            mutID = str(row['chr']) + \".\" +str(row['start']) + \".\" + str(row['ref']) + \".\" + str(row['var']) + \":\" + str(row['Hugo_Symbol']) + \":\" + str(driver_mut_dict[row['DriverMut']])\n",
    "            ccf = min(1, float(row['final_ccf'])) if row['cluster_clonality'] != 'clonal' else 1.0\n",
    "            #print(tID, regID, mutID, ccf)\n",
    "            #print(regID, ccf)\n",
    "            if ccf > 0:\n",
    "                tumour_regions[n][mutID] = ccf\n",
    "                if row['DriverMut']:\n",
    "                    all_drivs_found.append(row['Hugo_Symbol']) #add driver to list if it's found here, might be added more than once- record only the Hugo Symbol, NOT the specific mutation\n",
    "                    #print(mutID)\n",
    "                    if ccf == 1.0:\n",
    "                        if row['Hugo_Symbol'] in clonal_appearances_of_drivers:\n",
    "                            clonal_appearances_of_drivers[row['Hugo_Symbol']] += 1\n",
    "                        else:\n",
    "                            clonal_appearances_of_drivers[row['Hugo_Symbol']] = 1 #keep track of whether drivers are clonal\n",
    "        # print(tumour_regions[n])\n",
    "    np.save(tID+\"_mutdict.npy\", tumour_regions)\n",
    "\n",
    "    #now check whether drivers are clonal or subclonal\n",
    "    num_regions = len(unique_regions)\n",
    "    all_drivs_found = np.unique(all_drivs_found)\n",
    "    clonal_drivers = []\n",
    "    subclonal_drivers = []\n",
    "    \n",
    "    for driv in all_drivs_found:\n",
    "        if driv in clonal_appearances_of_drivers:\n",
    "            print(driv, clonal_appearances_of_drivers[driv], num_regions)\n",
    "            if clonal_appearances_of_drivers[driv] == num_regions: #found clonally everywhere\n",
    "                clonal_drivers.append(driv)\n",
    "        else:\n",
    "            subclonal_drivers.append(driv)\n",
    "    \n",
    "    np.save(base_filepath+\"/\"+tID+\"_driver_muts.npy\", all_drivs_found)\n",
    "    print(tID, \"clonal drivers\", clonal_drivers)\n",
    "    np.save(base_filepath+\"/\"+tID+\"_clonal_driver_muts.npy\", clonal_drivers)\n",
    "    np.save(base_filepath+\"/\"+tID+\"_subclonal_driver_muts.npy\", subclonal_drivers)\n",
    "\n",
    "np.save(\"all_tumour_names.npy\", all_tumour_names)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6413a3d2-44da-4351-9b7b-678320bc67ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "tumour_names = np.load(\"all_tumour_names.npy\", allow_pickle=True)\n",
    "print(len(tumour_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cf286-8281-410e-bc42-73f3bdf08e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that will do this for individual tumours\n",
    "\n",
    "#calculate output summary statistics for a given number of samples, excluding clonal mutations\n",
    "def calculate_output_stats_real_tumour(tumour_name):\n",
    "    mutdict = np.load(tumour_name + \"_mutdict.npy\", allow_pickle=True)\n",
    "    no_samples = len(mutdict)\n",
    "    all_muts = []\n",
    "    for dict in mutdict:\n",
    "        all_muts += list(dict.keys()) #look at all mutations seen in this sample\n",
    "    all_unique_mutations = np.unique(all_muts) #all mutations in all samples\n",
    "    mut_matrix = np.zeros((len(all_unique_mutations), no_samples))\n",
    "    for m, mut in enumerate(all_unique_mutations):\n",
    "        for n, dict in enumerate(mutdict):\n",
    "            if mut in dict:\n",
    "                mut_matrix[m][n] = dict[mut] #zero by default\n",
    "    #now proceed as with a simulated tumour, excluding clonal samples-- no read threshold\n",
    "    min_ccfs = np.min(mut_matrix, axis=1)\n",
    "    non_clonal_muts = np.where(min_ccfs < 1.0)[0] #not clonal everywhere\n",
    "    mut_matrix = mut_matrix[non_clonal_muts] #filter out all of the clonal ones\n",
    "    #now to actually calculate summary statistics!\n",
    "    #0. all mutations detected subclonally (i.e. with CCF < 1.0 in at least one sample)\n",
    "    no_muts = len(non_clonal_muts)\n",
    "    #1. all mutations detected in 1 sample only\n",
    "    appearances = np.count_nonzero(mut_matrix, axis=1)\n",
    "    private = np.where(appearances == 1)[0]\n",
    "    num_private = len(private)\n",
    "    #2-no_samples, ... number fixed in 1, ... no_samples-1 samples\n",
    "    fixed_muts = []\n",
    "    for s in range(1, no_samples):\n",
    "        fixed_muts.append(count_fixation_number(mut_matrix, s)) #count number fixed in s samples\n",
    "    #no_samples+1: number of mutations fixed AND private\n",
    "    private_ccfs = np.max(mut_matrix[private], axis=1) #the maximum CCF of a private mutation will be its CCF in that sample\n",
    "    fixed_and_private = np.where(private_ccfs == 1.0)[0]\n",
    "    num_fixed_private = len(fixed_and_private)\n",
    "    #no_samples + 2-2*no_samples-1- the number of mutations appearing in 2, ... no_samples samples\n",
    "    num_appearing = []\n",
    "    for s in range(2, no_samples+1):\n",
    "        num_appearing.append(len(np.where(appearances == s)[0]))\n",
    "    return no_samples, [no_muts, num_private] + fixed_muts + [num_fixed_private] + num_appearing    \n",
    "    \n",
    "\n",
    "tIDs = np.load(\"all_tumour_names.npy\", allow_pickle=True)\n",
    "\n",
    "print(len(tIDs))\n",
    "\n",
    "#assign tumours to a different bucket depending on the number of samples taken\n",
    "stats_by_sample_number = [[] for s in range(2, 9)]\n",
    "num_samples = {}\n",
    "for tumour_name in tIDs:\n",
    "    try:\n",
    "        no_samples, stats = calculate_output_stats_real_tumour(tumour_name)\n",
    "        if no_samples > 1:\n",
    "            num_samples[tumour_name] = no_samples\n",
    "            stats_by_sample_number[no_samples-2].append(stats)\n",
    "            np.save(base_filepath+\"/\"+tumour_name+\"_ss_4424.npy\", stats)\n",
    "            print(tumour_name, \"found\")\n",
    "        else:\n",
    "            print(tumour_name, \"too few samples\")\n",
    "            \n",
    "    except:\n",
    "        print(tumour_name, \"not found\")\n",
    "\n",
    "#print(overall_stats)\n",
    "\n",
    "for n, stat_matrix in enumerate(stats_by_sample_number):\n",
    "    np.save(\"cruk_\"+str(n+2)+\"_samples_stat.npy\", stat_matrix)\n",
    "\n",
    "np.save(\"num_samples_by_tumour_name.npy\", num_samples)\n",
    "#np.save(\"stat_index_by_tumour_name.npy\", stat_index_dict)\n",
    "#np.save(\"cruk_overall_stats.npy\", overall_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a002ce-8140-451c-8adf-ab6ca5c1659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRUK0030_Cluster2\n",
      "CRUK0223_Cluster1\n",
      "CRUK0223_Cluster2\n",
      "CRUK0372_Cluster1\n",
      "CRUK0372_Cluster2\n",
      "CRUK0555_Cluster2\n",
      "CRUK0586_Cluster1\n",
      "CRUK0586_Cluster2\n",
      "CRUK0620_Cluster1\n",
      "CRUK0620_Cluster2\n",
      "CRUK0704_Cluster1\n",
      "CRUK0704_Cluster2\n",
      "CRUK0704_Cluster3\n",
      "CRUK0721_Cluster2\n",
      "CRUK0881_Cluster1\n",
      "CRUK0881_Cluster2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"C:/Users/44749/Documents/PhD_work/datasets_for_analysis/tracerx_clinical_df.xlsx\")\n",
    "purity_df = pd.read_excel(\"C:/Users/44749/Documents/PhD_work/datasets_for_analysis/tx421_purity_ploidy.xlsx\")\n",
    "patient_df = pd.read_excel(\"C:/Users/44749/Documents/PhD_work/datasets_for_analysis/tracerx_patient_df.xlsx\")\n",
    "\n",
    "sex_codes = {'Male':0, 'Female':1}\n",
    "histology_codes = {'LUAD':0, 'LUSC':1, 'Other':2}\n",
    "smok_stat_codes = {'Smoker':0, 'Ex-Smoker':1, 'Never Smoked':2}\n",
    "\n",
    "num_samples = np.load(\"num_samples_by_tumour_name.npy\", allow_pickle=True).item()\n",
    "\n",
    "\n",
    "patient_index_dict = {} #record where all patients are in this list\n",
    "pcount = 0\n",
    "\n",
    "clinical_dfs = []\n",
    "\n",
    "unique_drivs = []\n",
    "for name in list(num_samples.keys()):\n",
    "    #load drivers\n",
    "    drivers_here = np.load(base_filepath+\"/\"+name+\"_driver_muts.npy\", allow_pickle=True)\n",
    "    #print(drivers_here)\n",
    "    unique_drivs += list(drivers_here)\n",
    "\n",
    "all_drivs = np.unique(unique_drivs)\n",
    "#assign each an index\n",
    "driv_index_dict = dict(zip(list(all_drivs), list(range(len(all_drivs)))))\n",
    "np.save(\"all_driv_identities.npy\", all_drivs)\n",
    "\n",
    "num_drivs = len(all_drivs)\n",
    "driver_matrix = []\n",
    "    \n",
    "\n",
    "for name in list(num_samples.keys()):\n",
    "    try:\n",
    "        drivers_here = np.load(base_filepath+\"/\"+name+\"_driver_muts.npy\", allow_pickle=True)\n",
    "        clonal_drivers_here = np.load(base_filepath+\"/\"+name+\"_clonal_driver_muts.npy\", allow_pickle=True)\n",
    "        subclonal_drivers_here = np.load(base_filepath+\"/\"+name+\"_subclonal_driver_muts.npy\", allow_pickle=True)\n",
    "        #print(name, \"clonal driver check\", clonal_drivers_here, len(clonal_drivers_here))\n",
    "        \n",
    "        age = df[df['tumour_id_muttable_cruk']==name]['age']\n",
    "        #print(name, age)\n",
    "        #print(age.iloc[0]\n",
    "        age = age.iloc[0]\n",
    "    \n",
    "        sex = df[df['tumour_id_muttable_cruk']==name]['clinical_sex']\n",
    "        sex = str(sex.iloc[0])\n",
    "        bin_sex = sex_codes[sex]\n",
    "        #print(bin_sex)\n",
    "        clinical_sex = bin_sex\n",
    "    \n",
    "        hist = str(df[df['tumour_id_muttable_cruk']==name]['histology_3'].iloc[0])\n",
    "        int_hist = histology_codes[hist]\n",
    "        histology = int_hist\n",
    "    \n",
    "        smok_stat = str(df[df['tumour_id_muttable_cruk']==name]['smoking_status_merged'].iloc[0])\n",
    "        smoking_status = smok_stat_codes[smok_stat]\n",
    "\n",
    "        pyears = df[df['tumour_id_muttable_cruk']==name]['pack_years']\n",
    "        pack_years= int(pyears.iloc[0])\n",
    "\n",
    "        #calculate average/minimum purity of all regions in the tumour\n",
    "        av_pur = np.average(purity_df[purity_df['tumour_id']==name]['Purity'])\n",
    "        min_pur = np.min(purity_df[purity_df['tumour_id']==name]['Purity'])\n",
    "\n",
    "        #take disease free survival time\n",
    "\n",
    "        dfs = patient_df[patient_df['tumour_id_muttable_cruk']==name]['dfs_time']\n",
    "        cens_dfs = patient_df[patient_df['tumour_id_muttable_cruk']==name]['cens_dfs']\n",
    "        dfs_any_event = patient_df[patient_df['tumour_id_muttable_cruk']==name]['dfs_time_any_event']\n",
    "        cens_dfs_any_event = patient_df[patient_df['tumour_id_muttable_cruk']==name]['cens_dfs_any_event']\n",
    "        dfs = float(dfs.iloc[0])\n",
    "        cens_dfs = float(cens_dfs.iloc[0])\n",
    "        dfs_any_event = float(dfs_any_event.iloc[0])\n",
    "        cens_dfs_any_event = float(cens_dfs_any_event.iloc[0])\n",
    "    \n",
    "        patient_index_dict[name] = pcount\n",
    "    \n",
    "    \n",
    "        clinical_dfs.append([age, clinical_sex, histology, smoking_status, pack_years, len(clonal_drivers_here), len(subclonal_drivers_here), av_pur, min_pur, dfs, cens_dfs, dfs_any_event, cens_dfs_any_event])\n",
    "        \n",
    "        driver_matrix_here = np.zeros(num_drivs, dtype=int)\n",
    "        for driv in list(drivers_here):\n",
    "            index = driv_index_dict[driv]\n",
    "            driver_matrix_here[index] = 1 #mark the presence of all detected drivers\n",
    "    \n",
    "        driver_matrix.append(driver_matrix_here)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        pcount += 1\n",
    "        \n",
    "\n",
    "    except:\n",
    "        print(name)\n",
    "\n",
    "np.save(\"patient_index_dict.npy\", patient_index_dict)\n",
    "np.save(\"clinical_var_matrix.npy\", clinical_dfs)\n",
    "np.save(\"clinical_driver_matrix.npy\", driver_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd499a-9819-47b5-aec4-e8cc94669ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
